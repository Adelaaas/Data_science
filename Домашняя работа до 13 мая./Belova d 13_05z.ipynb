{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(42) # воспроизводство условия/результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2   2         20       756  2549     9     7   \n",
       "1       0.7        136        3   6        905      1988  2631    17     3   \n",
       "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
       "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
       "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
       "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
       "1998    0.1        145        5   5        336       670   869    18    10   \n",
       "1999    0.9        168        6  16        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  \n",
       "0            19        0             0     1  \n",
       "1             7        1             1     0  \n",
       "2             9        1             1     0  \n",
       "3            11        1             0     0  \n",
       "4            15        1             1     0  \n",
       "...         ...      ...           ...   ...  \n",
       "1995         19        1             1     0  \n",
       "1996         16        1             1     1  \n",
       "1997          5        1             1     0  \n",
       "1998         19        1             1     1  \n",
       "1999          2        1             1     1  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,0:20]  # y = ax [диапазон строк, диапазон столбцов]\n",
    "Y = df.iloc[:,20] \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean        1.500000\n",
       "std         1.118314\n",
       "min         0.000000\n",
       "25%         0.750000\n",
       "50%         1.500000\n",
       "75%         2.250000\n",
       "max         3.000000\n",
       "Name: price_range, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price_range'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y = np_utils.to_categorical(Y, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(13, input_dim=20, activation='relu'))\n",
    "# input_shape = (3,3)\n",
    "# add - добавляет какой-то слой к нашей нейронной сети\n",
    "# input_dim - количество признаков\n",
    "# activation - функция активации\n",
    "# Первые числа, передаваемые Dense, это количества нейронов в слое\n",
    "\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# выходной слой\n",
    "\n",
    "model.add(Dense(4, activation='softmax')) # возращает вероятность принадлежность к классу\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                273       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перед тем, как начать тренировать модель, ее нужно скомпилировать при помощи метода compile()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy', 'Recall'])\n",
    "\n",
    "# Методу передается три параметра:\n",
    "# loss – функция потерь – объект, который модель стремиться минимизировать;\n",
    "# optimizer – оптимизатор, мы используем встроенный метод стохастической оптимизации adam\n",
    "# metrics – список метрик оптимизации, для задач классификации используется метрику 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 815us/step - loss: 1.0011 - accuracy: 0.5665 - recall: 0.4060\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.8974 - accuracy: 0.5890 - recall: 0.4405\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 656us/step - loss: 0.8648 - accuracy: 0.6025 - recall: 0.4565\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.8670 - accuracy: 0.5965 - recall: 0.4605\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.8759 - accuracy: 0.5930 - recall: 0.4490\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 670us/step - loss: 0.8706 - accuracy: 0.5970 - recall: 0.4625\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 745us/step - loss: 0.8151 - accuracy: 0.6080 - recall: 0.4715\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.8174 - accuracy: 0.6240 - recall: 0.4890\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.7704 - accuracy: 0.6280 - recall: 0.4940\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 670us/step - loss: 0.7735 - accuracy: 0.6250 - recall: 0.4990\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 684us/step - loss: 0.7944 - accuracy: 0.6155 - recall: 0.4830\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.7544 - accuracy: 0.6375 - recall: 0.5185\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 684us/step - loss: 0.7264 - accuracy: 0.6395 - recall: 0.5090\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.7133 - accuracy: 0.6575 - recall: 0.5285\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 684us/step - loss: 0.7157 - accuracy: 0.6520 - recall: 0.5340\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 657us/step - loss: 0.7086 - accuracy: 0.6605 - recall: 0.5415\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.7507 - accuracy: 0.6495 - recall: 0.5300\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 685us/step - loss: 0.6990 - accuracy: 0.6615 - recall: 0.5485\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.6880 - accuracy: 0.6980 - recall: 0.5545\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.6715 - accuracy: 0.7015 - recall: 0.5690\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.6668 - accuracy: 0.7025 - recall: 0.5740\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 752us/step - loss: 0.6861 - accuracy: 0.7020 - recall: 0.5550\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.6814 - accuracy: 0.6970 - recall: 0.5730\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 735us/step - loss: 0.6656 - accuracy: 0.7090 - recall: 0.5735\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 779us/step - loss: 0.6437 - accuracy: 0.7070 - recall: 0.5610\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 717us/step - loss: 0.6650 - accuracy: 0.7010 - recall: 0.5625\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 698us/step - loss: 0.6888 - accuracy: 0.7160 - recall: 0.5795\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.6302 - accuracy: 0.7205 - recall: 0.5860\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 794us/step - loss: 0.6392 - accuracy: 0.7170 - recall: 0.5830\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 784us/step - loss: 0.6459 - accuracy: 0.7225 - recall: 0.5735\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 833us/step - loss: 0.6152 - accuracy: 0.7270 - recall: 0.5945\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 739us/step - loss: 0.6926 - accuracy: 0.7070 - recall: 0.5725\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.6281 - accuracy: 0.7350 - recall: 0.5875\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.6051 - accuracy: 0.7370 - recall: 0.5945\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.5972 - accuracy: 0.7410 - recall: 0.6105\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.5994 - accuracy: 0.7460 - recall: 0.6055\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 760us/step - loss: 0.6009 - accuracy: 0.7375 - recall: 0.6020\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.6030 - accuracy: 0.7340 - recall: 0.6080\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.6221 - accuracy: 0.7490 - recall: 0.6200\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.6271 - accuracy: 0.7230 - recall: 0.5875\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.6001 - accuracy: 0.7465 - recall: 0.6330\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.5850 - accuracy: 0.7500 - recall: 0.6040\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.5772 - accuracy: 0.7590 - recall: 0.6350\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 760us/step - loss: 0.5924 - accuracy: 0.7390 - recall: 0.6150\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.5894 - accuracy: 0.7505 - recall: 0.6235\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 696us/step - loss: 0.5802 - accuracy: 0.7525 - recall: 0.6320\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.5581 - accuracy: 0.7615 - recall: 0.6510\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 739us/step - loss: 0.5712 - accuracy: 0.7480 - recall: 0.6500\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 662us/step - loss: 0.5889 - accuracy: 0.7465 - recall: 0.6500\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.5778 - accuracy: 0.7535 - recall: 0.6530\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 736us/step - loss: 0.5959 - accuracy: 0.7470 - recall: 0.6655\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.5560 - accuracy: 0.7605 - recall: 0.6875\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 749us/step - loss: 0.5662 - accuracy: 0.7585 - recall: 0.6895\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 677us/step - loss: 0.5558 - accuracy: 0.7625 - recall: 0.7055\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.5772 - accuracy: 0.7470 - recall: 0.6775\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.5627 - accuracy: 0.7690 - recall: 0.7025\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 684us/step - loss: 0.5670 - accuracy: 0.7550 - recall: 0.6815\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 661us/step - loss: 0.5774 - accuracy: 0.7510 - recall: 0.6975\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.5700 - accuracy: 0.7665 - recall: 0.7065\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.5455 - accuracy: 0.7705 - recall: 0.7230\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.5479 - accuracy: 0.7640 - recall: 0.7110\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.5402 - accuracy: 0.7725 - recall: 0.7200\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.5531 - accuracy: 0.7735 - recall: 0.7265\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.5300 - accuracy: 0.7810 - recall: 0.7365\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 685us/step - loss: 0.5237 - accuracy: 0.7795 - recall: 0.7285\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 691us/step - loss: 0.5265 - accuracy: 0.7850 - recall: 0.7410\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 684us/step - loss: 0.5578 - accuracy: 0.7595 - recall: 0.7225\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.5446 - accuracy: 0.7690 - recall: 0.7220\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 741us/step - loss: 0.5675 - accuracy: 0.7470 - recall: 0.7155\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.5384 - accuracy: 0.7690 - recall: 0.7255\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 730us/step - loss: 0.5191 - accuracy: 0.7840 - recall: 0.7490\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 685us/step - loss: 0.5184 - accuracy: 0.7855 - recall: 0.7490\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.5271 - accuracy: 0.7790 - recall: 0.7455\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.5271 - accuracy: 0.7750 - recall: 0.7355\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 718us/step - loss: 0.5307 - accuracy: 0.7715 - recall: 0.7375\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 731us/step - loss: 0.5177 - accuracy: 0.7855 - recall: 0.7540\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 768us/step - loss: 0.5163 - accuracy: 0.7765 - recall: 0.7510\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 730us/step - loss: 0.5198 - accuracy: 0.7755 - recall: 0.7395\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.5361 - accuracy: 0.7845 - recall: 0.7605\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 730us/step - loss: 0.5208 - accuracy: 0.7730 - recall: 0.7390\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 750us/step - loss: 0.5310 - accuracy: 0.7715 - recall: 0.7390\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.5139 - accuracy: 0.7830 - recall: 0.7510\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.5213 - accuracy: 0.7755 - recall: 0.7445\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.4975 - accuracy: 0.7845 - recall: 0.7580\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.4970 - accuracy: 0.7880 - recall: 0.7610\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 729us/step - loss: 0.5186 - accuracy: 0.7720 - recall: 0.7395\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.5123 - accuracy: 0.7755 - recall: 0.7525\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.5074 - accuracy: 0.7785 - recall: 0.7525\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 736us/step - loss: 0.5052 - accuracy: 0.7880 - recall: 0.7660\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.4905 - accuracy: 0.7935 - recall: 0.7665\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.5241 - accuracy: 0.7755 - recall: 0.7540\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 655us/step - loss: 0.4967 - accuracy: 0.7870 - recall: 0.7635\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.5128 - accuracy: 0.7735 - recall: 0.7560\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 744us/step - loss: 0.4937 - accuracy: 0.7860 - recall: 0.7590\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 862us/step - loss: 0.4923 - accuracy: 0.7935 - recall: 0.7635\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 731us/step - loss: 0.5011 - accuracy: 0.7875 - recall: 0.7685\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.4991 - accuracy: 0.7995 - recall: 0.7715\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.4915 - accuracy: 0.7925 - recall: 0.7715\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.5078 - accuracy: 0.7885 - recall: 0.7640\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 663us/step - loss: 0.4865 - accuracy: 0.7910 - recall: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf62f09100>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f3c7e85ece9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \"\"\"\n\u001b[1;32m-> 1735\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1736\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1434\u001b[0m                                     pos_label)\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1264\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,0:20]  # y = ax [диапазон строк, диапазон столбцов]\n",
    "Y = df.iloc[:,20] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\" , accuracy_score(y_test, y_pred))\n",
    "print(\"Recall\" ,recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) датасет: 2000 rows × 21 columns 2) датасет имеет набор из 4 классов по 500 значений каждый 3) классификация - определение принадлежности к тому или иному классу(да грубовато) 4) ансамбль - использование взаимодействующих друг с другом моделей, чаще всего базовых 5) нейронная сеть - это искусственное воссоздание работы мозга для решения определенных задач 6) метрики классификации - accuracy, precision, recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
